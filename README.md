# Robot Car Racing Competition

## Overview
The **Robot Car Racing Competition** is a subject as part of the Master's program in Mechatronics and Embedded System at RWU (Ravensburg-Weingarten University of Applied Sciences). This project was guided and supervised by **Mr. Tobias Niedermaier**. 

The primary objective of this course is to design and program an autonomous robot car capable of solving a series of tasks using computer vision, LiDAR and Camera sensors, and embedded systems. 

### Authors
- **Vardhan Mistry**
- **Rajveersinh Suratiya**
- **Hardik Rathwa**

---

## Repository Structure
This repository is organized into four main folders, one for each task of the competition. Each folder contains:

1. The Python code implementing the task.
2. A README file explaining the task-specific implementation.
3. Videos and photos demonstrating the robot solving the task.

### Folder Structure
```plaintext
Robot-Car-Racing-Competition/
â”‚
â”œâ”€â”€ Task1_Line_Following/
â”‚   â”œâ”€â”€ task1_line_following.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ videos/
â”‚   â””â”€â”€ images/
â”‚
â”œâ”€â”€ Task2_task2_obstacle_avoidance/
â”‚   â”œâ”€â”€ task2_lidar_stop.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ videos/
â”‚   â””â”€â”€ images/
â”‚
â”œâ”€â”€ Task3_Color_Cube_Detection/
â”‚   â”œâ”€â”€ task3_color_cube_detection.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ videos/
â”‚   â””â”€â”€ images/
â”‚
â”œâ”€â”€ Task4_ArUco_Cube_Detection/
â”‚   â”œâ”€â”€ task4_aruco_cube_detection.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ videos/
â”‚   â””â”€â”€ images/
â”‚
â”œâ”€â”€ README.md  (This File)
â””â”€â”€ Line.pdf  (Line layout reference)
```

---

### ğŸ› ï¸ Common Hardware Requirements

- Raspberry Pi 4  
- Pi Camera or compatible USB camera  
- RPLidar sensor (e.g., RPLidar A1/A2)  
- Motor driver (e.g., L298N)  
- DC motors and chassis  
- Power supply and wiring  

---

### ğŸ’» Common Software Requirements

- Python 3.x  
- OpenCV library  
- RPi.GPIO library  
- Adafruit RPLidar library  

---

## General Description of Tasks

### Task 1: Line Following
The robot uses a camera to follow a line created using sheets of paper (described in `Line.pdf`). The algorithm processes the camera feed, detects the line, and adjusts the robot's movement to stay on track. Thresholds for line detection were fine-tuned for optimal performance in H216.

---

### Task 2: LiDAR-Based Stopping (obstacle_avoidance)
The robot uses a LiDAR sensor to detect obstacles and stop 20 cm in front of them. This feature works seamlessly while the robot is following the line from Task 1.

---

### Task 3: Color Cube Detection
The robot detects and moves towards green and red cubes, stopping at different distances:
- 20 cm for green cubes
- 40 cm for red cubes

If no cubes are visible, the robot remains stationary. If both cubes are visible, the robot moves toward the closer one.

---

### Task 4: ArUco Marker Cube Detection
The robot detects cubes marked with ArUco markers (6x6 ID 0 and ID 1) and stops at specific distances:
- 20 cm for ID 0
- 40 cm for ID 1

Similar to Task 3, if both markers are visible, the robot approaches the closer one.

---

## Technologies and Tools
- **Programming Language**: Python
- **Libraries**: OpenCV, NumPy, RPi.GPIO
- **Hardware**: Raspberry Pi 4, Camera

---

## How to Run the Code
Each task folder contains a `README.md` file with detailed instructions for running the corresponding code. In general:

1. Clone the repository:
   ```bash
   git clone https://github.com/VArdhan1303/Robot-Car-Racing-Competition.git
   cd Robot-Car-Racing-Competition
   ```

2. Navigate to the desired task folder:
   ```bash
   cd Task1_Line_Following
   ```

3. Run the Python script:
   ```bash
   python3 task1_line_following.py
   ```

4. Follow instructions in the task-specific `README.md` for setup and testing.

---

## Notes
- This algorithm and code will work only on Raspberry Pi 4. If you want to run it on other hardware, you will need to modify the code according to the hardware specifications.
- This project is intended solely for learning and expanding knowledge in the ADAS (Advanced Driver-Assistance Systems) field.
- You are not permitted to copy or publish this work without our explicit permission.

---

## Acknowledgements
We express our gratitude to **Mr. Tobias Niedermaier** for his guidance and support throughout this project. The course provided invaluable experience in robotics, computer vision, and sensor integration.
